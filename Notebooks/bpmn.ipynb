{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from typing import OrderedDict, List\n",
    "from collections import OrderedDict\n",
    "import abc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPMNParser():\n",
    "    \n",
    "    def simple_load(self, file_name:str)->OrderedDict:\n",
    "        with open(file_name,\"r\") as file:\n",
    "            process = xmltodict.parse(file.read()).get(\"bpmn:definitions\", {}).get(\"bpmn:process\", {})\n",
    "        return process\n",
    "          \n",
    "    def load(self,file_name:str)->OrderedDict:\n",
    "        process = self.simple_load(file_name)\n",
    "        needed_checks = [self._check_start, self._check_end, self._check_task, self._check_exclusiveGateways, self._check_inclusiveGateways, self._check_parallelGateways]\n",
    "        for check in needed_checks:\n",
    "            process = check(process)\n",
    "        return process\n",
    "    \n",
    "    def _transform_outgoing(self, outgoing, process):\n",
    "        if type(outgoing) == str:\n",
    "            flow = self.find_flow(process,outgoing)\n",
    "            return {\"@id\": outgoing, \"@name\":flow.get(\"@name\", \"no_name\"),\"@targetRef\": flow.get(\"@targetRef\", None)}\n",
    "        else:\n",
    "            for key, flow_id in enumerate(outgoing):\n",
    "                flow = self.find_flow(process, flow_id)\n",
    "                outgoing[key] = {\"@id\": flow_id, \"@name\":flow.get(\"@name\", \"no_name\"),\"@targetRef\": flow.get(\"@targetRef\", None)}  \n",
    "        return outgoing\n",
    "    \n",
    "    def _check_start(self, process:OrderedDict)->OrderedDict:\n",
    "        start = process.get(\"bpmn:startEvent\", None)\n",
    "        assert type(start) == OrderedDict, \"No Start Event found or multiple startevents\"\n",
    "        assert start.get(\"bpmn:incoming\", None) is None, \"startEvent can't have incoming flows\"\n",
    "        outgoing = start.get(\"bpmn:outgoing\", None)\n",
    "        assert type(outgoing) == str, \"Start Event has mulitple Outgoing events or isn't connected\"\n",
    "        process[\"bpmn:startEvent\"][\"bpmn:outgoing\"] = self._transform_outgoing(outgoing, process)\n",
    "        return process\n",
    "    \n",
    "    def _check_end(self, process):\n",
    "        end = process.get(\"bpmn:endEvent\", None)\n",
    "        assert end is not None, \"Process needs an EndEvent!\"\n",
    "        if type(end) == OrderedDict:end = [end]\n",
    "        for el in end:\n",
    "            assert (el.get(\"bpmn:outgoing\", None)) is None, \"EndEvents cant have outgoing flows\"\n",
    "            inc = el.get(\"bpmn:incoming\", None)\n",
    "            assert type(inc) == str, \"EndEvents cant have multiple incoming flows please use a closing Gate\"\n",
    "        return process\n",
    "    \n",
    "    def _check_task(self, process:OrderedDict)->OrderedDict:\n",
    "        task = process.get(\"bpmn:task\", None)\n",
    "        if task is not None and type(task) == OrderedDict:\n",
    "            assert type(task.get(\"@name\", None)) is not None, \"Task needs Name/Operation to be used in any meaningful way lol\"\n",
    "            assert type(task.get(\"bpmn:incoming\", None)) == str, \"Tasks needs exactly one incoming flow\"\n",
    "            out = task.get(\"bpmn:outgoing\", None) \n",
    "            assert type(out) == str, \"Task needs exactly one outgoing flow\"\n",
    "            process[\"bpmn:task\"][i][\"bpmn:outgoing\"] = self._transform_outgoing(out,process)\n",
    "        elif type(task) != list:return process\n",
    "        else:\n",
    "            for i,t in enumerate(task):\n",
    "                assert type(t.get(\"@name\", None)) is not None, \"Task needs Name/Operation to be used in any meaningful way lol\"\n",
    "                assert type(t.get(\"bpmn:incoming\", None)) == str, \"Tasks needs exactly one incoming flow\"\n",
    "                out = t.get(\"bpmn:outgoing\", None) \n",
    "                assert type(out) == str, \"Task needs exactly one outgoing flow\"\n",
    "                process[\"bpmn:task\"][i][\"bpmn:outgoing\"] = self._transform_outgoing(out,process)\n",
    "        return process\n",
    "    \n",
    "    def _check_Gateways(self, process:OrderedDict, gate_type:str, default_op:str, check:bool)->OrderedDict:\n",
    "        gateways = process.get(gate_type, None)\n",
    "        if gateways is None: return process\n",
    "        elif type(gateways) == list:\n",
    "            for key,gateway in enumerate(gateways):\n",
    "                inc = gateway.get(\"bpmn:incoming\", None)\n",
    "                out = gateway.get(\"bpmn:outgoing\", None)\n",
    "                assert (inc is not None or out is not None) and type(inc) != type(out), \"gateways should be conncted properly\"\n",
    "                if type(inc) == list:\n",
    "                    assert type(out) == str, \"Closing Gate can't be also an Opening Gate\"\n",
    "                    process[gate_type][key][\"@opening\"] = False \n",
    "                    process[gate_type][key][\"bpmn:outgoing\"] = self._transform_outgoing(out, process)\n",
    "                    #set default operation \n",
    "                    if gateway.get(\"@name\", None) is None:\n",
    "                        process[gate_type][key][\"@name\"] = default_op\n",
    "                else:\n",
    "                    assert type(inc) == str, \"Opening Gate can't be also a Closing Gate\"\n",
    "                    process[gate_type][key][\"@opening\"] = True\n",
    "                    process[gate_type][key][\"bpmn:outgoing\"] = self._transform_outgoing(out, process)\n",
    "                    if check:\n",
    "                        default = gateway.get(\"@default\", None)\n",
    "                        for o in out:\n",
    "                            assert o.get(\"@name\") != \"no_name\" or o.get(\"@id\") == default, \"Opening Gate needs all outgoing flows to have an Condition or be a default Flow\"\n",
    "                \n",
    "        else:\n",
    "            #determine if opening or closing Gate and see if check if all needed infos are present\n",
    "            inc = gateways.get(\"bpmn:incoming\", None)\n",
    "            out = gateways.get(\"bpmn:outgoing\", None)\n",
    "            assert (inc is not None or out is not None) and type(inc) != type(out), \"gateways should be conncted properly\"\n",
    "            if type(inc) == list:\n",
    "                assert type(out) == str, \"Closing Gate can't be also an Opening Gate\"\n",
    "                process[gate_type][\"@opening\"] = False \n",
    "                process[gate_type][\"bpmn:outgoing\"] = self._transform_outgoing(out, process)\n",
    "                #set default operation \n",
    "                if gateways.get(\"@name\", None) is None:\n",
    "                    process[gate_type][\"@name\"] = default_op\n",
    "            else:\n",
    "                assert type(inc) == str, \"Opening Gate can't be also a Closing Gate\"\n",
    "                process[gate_type][\"@opening\"] = True\n",
    "                process[gate_type][\"bpmn:outgoing\"] = self._transform_outgoing(out, process)\n",
    "                \n",
    "                if check:\n",
    "                    default = gateways.get(\"@default\", None)\n",
    "                    for o in out:\n",
    "                        assert o.get(\"@name\") != \"no_name\" or o.get(\"@id\") == default, \"Opening Gate needs all outgoing flows to have an Condition or be a default Flow\"\n",
    "                        \n",
    "        return process\n",
    "    \n",
    "    def _check_exclusiveGateways(self, process):\n",
    "        return self._check_Gateways(process, \"bpmn:exclusiveGateway\", \"passtrough\", True)\n",
    "\n",
    "    def _check_inclusiveGateways(self, process):\n",
    "        return self._check_Gateways(process, \"bpmn:inclusiveGateway\", \"concat\", True)\n",
    "\n",
    "    def _check_parallelGateways(self, process):\n",
    "        return self._check_Gateways(process, \"bpmn:parallelGateway\", \"join\", False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def find_flow(self,process, flow_id):\n",
    "        for flow in process.get(\"bpmn:sequenceFlow\"):\n",
    "            if flow.get(\"@id\") == flow_id:\n",
    "                return flow\n",
    "        return None\n",
    "    def find_element(self, process, element_id)->dict:\n",
    "        for key in process:\n",
    "            if not key.startswith(\"@\") and key != \"bpmn:sequenceFlow\":\n",
    "                if type(process[key]) == list:\n",
    "                    for count,item in enumerate(process[key]):\n",
    "                        if process[key][count][\"@id\"] == element_id:\n",
    "                            return {\"type\":key,\n",
    "                                    \"information\":process[key][count]}\n",
    "                else:\n",
    "                    if process[key][\"@id\"] == element_id:\n",
    "                            return {\"type\":key,\n",
    "                                    \"information\":process[key]}\n",
    "        return None\n",
    "                                \n",
    "            \n",
    "parser = BPMNParser()\n",
    "test = parser.load(\"all_elemts.bpmn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "class Token():\n",
    "    \n",
    "    def __init__(self, context:str):\n",
    "        self.data = None\n",
    "        self.context:str = context\n",
    "        self.taken_paths = 1\n",
    "        self.id = str(uuid4())\n",
    "    def add_context(self,element:str)->None:\n",
    "        self.context = f\"{self.context}-->{element}\"\n",
    "    def __repr__(self):\n",
    "        return f\"Token: {self.id}, Path taken: {self.context}\"\n",
    "    \n",
    "    def __deepcopy__(self, memo):\n",
    "        copied = Token(self.context)\n",
    "        #here copy dataframe\n",
    "        return copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPMNComponent:\n",
    "    \n",
    "    def __init__(self,process_definition:OrderedDict):\n",
    "        self.id = process_definition.get(\"@id\")\n",
    "        self.name = process_definition.get(\"@name\", \"no_name\")\n",
    "        self.incoming = process_definition.get(\"bpmn:incoming\", None)\n",
    "        self.outgoing = process_definition.get(\"bpmn:outgoing\", None)\n",
    "\n",
    "    @abc.abstractclassmethod\n",
    "    def execute(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartEvent(BPMNComponent):\n",
    "       \n",
    "    def execute(self):\n",
    "        token = Token(f\"StartEvent :{self.id}{'('+self.name+')' if self.name != 'no_name' else ''}\") \n",
    "        target = self.outgoing\n",
    "        print(token)\n",
    "        assert target[\"@targetRef\"] != None, \"missing refernce!!\"\n",
    "        return {\n",
    "        \"operation\":\"add\",\n",
    "        \"elements\" : [{\"id\":target[\"@targetRef\"], \"token\":token}]\n",
    "        }\n",
    "st = StartEvent(test.get(\"bpmn:startEvent\"))\n",
    "st.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndEvent(BPMNComponent):\n",
    "    \n",
    "    def __init__(self,process_definition:OrderedDict, token:Token):\n",
    "        self.token = token\n",
    "        super().__init__(process_definition)\n",
    "       \n",
    "    def execute(self):\n",
    "        self.token.add_context(f\"EndEvent:{self.id}{'('+self.name+')' if self.name != 'no_name' else ''}\")\n",
    "        print(self.token)\n",
    "        return {\n",
    "        \"operation\":\"end\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task(BPMNComponent):\n",
    "    \n",
    "    def __init__(self,process_definition:OrderedDict, token:Token):\n",
    "        self.token = token\n",
    "        super().__init__(process_definition)\n",
    "    \n",
    "    def execute(self):\n",
    "        self.token.add_context(f\"Task:{self.id}{'('+self.name+')' if self.name != 'no_name' else ''}\")\n",
    "        print(self.token)\n",
    "        # here perform transformation action based on task name\n",
    "        target = self.outgoing\n",
    "        assert target[\"@targetRef\"] != None, \"missing refernce!!\"\n",
    "        return {\n",
    "        \"operation\":\"add\",\n",
    "        \"elements\" : [{\"id\":target[\"@targetRef\"], \"token\":self.token}]\n",
    "        }\n",
    "    def __lt__(self, other):\n",
    "        #here it needs to be definied which task should be done first lol\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExclusiveGateway(BPMNComponent):\n",
    "    def __init__(self, process_definition:OrderedDict, token:Token):\n",
    "        self.token = [token]\n",
    "        self.opening = process_definition.get(\"@opening\", False)\n",
    "        self.default = process_definition.get(\"@default\", None)\n",
    "        super().__init__(process_definition)\n",
    "    \n",
    "    def execute(self):\n",
    "        for token in self.token:\n",
    "            token.add_context(f\"ExclusiveGateway:{self.id}{'('+self.name+')' if self.name != 'no_name' else ''}\")\n",
    "            print(token)\n",
    "        if self.opening:\n",
    "            for el in self.outgoing:\n",
    "                if el.get(\"@id\", None) == self.default:\n",
    "                    return {\n",
    "                            \"operation\":\"add\",\n",
    "                            \"elements\" : [{\"id\":el[\"@targetRef\"], \"token\":self.token[0]}]\n",
    "                            }\n",
    "        else:\n",
    "            #here you could customize the behaviour with some keywords\n",
    "            new_token = self.token[0]\n",
    "            return {\n",
    "                    \"operation\":\"add\",\n",
    "                    \"elements\" : [{\"id\":self.outgoing[\"@targetRef\"], \"token\":new_token}]\n",
    "                    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "class ParallelGateway(BPMNComponent):\n",
    "    def __init__(self, process_definition:OrderedDict, token: Token):\n",
    "        self.token = [token]\n",
    "        self.opening = process_definition.get(\"@opening\", False)\n",
    "        super().__init__(process_definition)\n",
    "        \n",
    "    def execute(self):\n",
    "        for token in self.token:\n",
    "            token.add_context(f\"ParallelGateway:{self.id}{'('+self.name+')' if self.name != 'no_name' else ''}\")\n",
    "            print(token)\n",
    "        if self.opening:\n",
    "            new_paths = len(self.outgoing)\n",
    "            tba = [{\"id\":el[\"@targetRef\"], \"token\":copy.deepcopy(self.token[0])} for el in self.outgoing]\n",
    "            for key, obj in enumerate(tba):\n",
    "                # print(key, obj)\n",
    "                tba[key][\"token\"].taken_paths = new_paths\n",
    "            return {\"operation\":\"add\", \"elements\":tba}\n",
    "        else:\n",
    "            token_len = len(self.token)\n",
    "            if token_len == self.token[0].taken_paths:\n",
    "                #do stuff\n",
    "                new_token = self.token[0]\n",
    "                new_token.taken_paths = 1\n",
    "                return {\n",
    "                        \"operation\":\"add\",\n",
    "                        \"elements\" : [{\"id\":self.outgoing[\"@targetRef\"], \"token\":new_token}]\n",
    "                        }\n",
    "            else:\n",
    "                return {\"operation\":\"repush\"}\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "class InclusiveGateway(BPMNComponent):\n",
    "    def __init__(self, process_definition:OrderedDict, token: Token):\n",
    "        self.token = [token]\n",
    "        self.opening = process_definition.get(\"@opening\", False)\n",
    "        self.default = process_definition.get(\"@default\", None)\n",
    "        super().__init__(process_definition)\n",
    "        \n",
    "    def execute(self):\n",
    "        for token in self.token:\n",
    "            token.add_context(f\"InclusiveGateway:{self.id}{'('+self.name+')' if self.name != 'no_name' else ''}\")\n",
    "            print(token)\n",
    "        if self.opening:\n",
    "            tba = [{\"id\":el[\"@targetRef\"], \"token\":copy.deepcopy(self.token[0])} for el in self.outgoing if el[\"@id\"] == self.default]\n",
    "            for key, obj in enumerate(tba):\n",
    "                # print(key, obj)\n",
    "                tba[key][\"token\"].taken_paths = len(tba)\n",
    "            return {\"operation\":\"add\", \"elements\":tba}\n",
    "        else:\n",
    "            token_len = len(self.token)\n",
    "            if token_len == self.token[0].taken_paths:\n",
    "                #do stuff\n",
    "                new_token = self.token[0]\n",
    "                new_token.taken_paths = 1\n",
    "                return {\n",
    "                        \"operation\":\"add\",\n",
    "                        \"elements\" : [{\"id\":self.outgoing[\"@targetRef\"], \"token\":new_token}]\n",
    "                        }\n",
    "            else:\n",
    "                return {\"operation\":\"repush\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq \n",
    "\n",
    "class BPMNEngine():\n",
    "    def __init__(self,file_name:str):\n",
    "        self.parser = BPMNParser()\n",
    "        self.process = self.parser.load(file_name)\n",
    "        self.elements = []\n",
    "        self.find_start()\n",
    "    \n",
    "    def find_start(self):\n",
    "        start = self.process.get(\"bpmn:startEvent\")\n",
    "        heapq.heappush(self.elements, (1,StartEvent(start)))\n",
    "        \n",
    "    def run(self):\n",
    "        while self.elements:\n",
    "            prio,cur = heapq.heappop(self.elements)\n",
    "            print(prio, cur)\n",
    "            next_step = cur.execute()\n",
    "            if next_step[\"operation\"] == \"add\":\n",
    "                for element in next_step[\"elements\"]:\n",
    "                    self.add(element)\n",
    "            elif next_step[\"operation\"] == \"repush\":\n",
    "                print(f\"{cur} was repushed with prio: {prio+1}\")\n",
    "                heapq.heappush(self.elements, (prio+1, cur))\n",
    "            elif next_step[\"operation\"] == \"end\":\n",
    "                if len(self.elements) == 0:\n",
    "                    print(\"Process ended\")\n",
    "            else:\n",
    "                pass\n",
    "    def add(self, next_element):\n",
    "        #check if element is already in queue\n",
    "        for prio, el in self.elements:\n",
    "            if el.id == next_element[\"id\"]:\n",
    "                el_type = type(el)\n",
    "                if el_type == ParallelGateway or el_type == ExclusiveGateway or el_type == InclusiveGateway:\n",
    "                    el.token.append(next_element[\"token\"])\n",
    "                return\n",
    "        element = self.parser.find_element(self.process, next_element[\"id\"])\n",
    "        # print(element)\n",
    "        if element[\"type\"] == \"bpmn:task\":\n",
    "            heapq.heappush(self.elements,(1,Task(element[\"information\"], next_element[\"token\"])))\n",
    "        elif element[\"type\"] == \"bpmn:exclusiveGateway\":\n",
    "            heapq.heappush(self.elements, (5,ExclusiveGateway(element[\"information\"], next_element[\"token\"])))\n",
    "        elif element[\"type\"] == \"bpmn:parallelGateway\":\n",
    "            heapq.heappush(self.elements, (5,ParallelGateway(element[\"information\"], next_element[\"token\"])))\n",
    "        elif element[\"type\"] == \"bpmn:inclusiveGateway\":\n",
    "            heapq.heappush(self.elements, (5,InclusiveGateway(element[\"information\"], next_element[\"token\"])))\n",
    "        elif element[\"type\"] == \"bpmn:endEvent\":\n",
    "            heapq.heappush(self.elements, (10,EndEvent(element[\"information\"], next_element[\"token\"])))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "engine = BPMNEngine(\"all_elemts.bpmn\")   \n",
    "engine.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 16), match='doNothing(1,2,3)'>\n",
      "<re.Match object; span=(0, 16), match='doNothing(1,2,3)'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = \"doNothing(1,2,3)\"\n",
    "r = re.match(\"(\\w+)\\([a-zA-Z0-9_:\\[\\]=, \"\".]*\\)\", s)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7a3a8ab5c229a5fe0b48dd28d0f9cf3b05548e3124458cae845ffec60fd2e06"
  },
  "kernelspec": {
   "display_name": "python3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
